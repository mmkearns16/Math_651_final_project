---
title: "Math 651 Final Project"
author: "Mary Peng, Hillary Dunn, and Max Kearns"
date: "December 17, 2018"
output:
  pdf_document:
    number_sections: yes
---

```{r setup, include=FALSE, cache = T}
knitr::opts_chunk$set(echo = FALSE, comment = NA)
base <-read.csv('data/base_data.csv', stringsAsFactors = F)
P__disp <- function(x) {
  pr <- sum(residuals(x, type="pearson")^2)
  dispersion <- pr/x$df.residual
  c(pr, dispersion)
}
library(dplyr)
library(qpcR)
library(MuMIn)
base.total = base[which(base$year!=2016),]
Olympic = base.total[,c(2,3,4,5,6,7,8)]
#Clean the data (Mary to add)
#Make new dataframe with GDP / capita
Olympic_v2 <- data.frame(year = Olympic$year, country = Olympic$country, count = Olympic$count, log_pop = log(Olympic$pop), log_gdp_per_cap = log(Olympic$gdp/Olympic$pop), host = Olympic$host, comm_soviet = Olympic$comm_soviet, log_count = log(Olympic$count))
```

# Abstract 

# Introduction

Every four summers, the Olympic Games become the center of the world’s attention, as elite athletes seek honor for both themselves and for their countries. Many countries associate tremendous national pride with their medal counts, since a nation’s athletic competence also projects its soft power. 

Given the fierce competition and high profile nature of medal counts, one may wonder what factors influence the number of medals that a country wins at the summer Olympics. Certainly countries with the largest economies and populations, such as the United States and China, commonly dominate the top of the billboard. However, Azerbaijan, which ranks 91st in population and 72nd in total GDP, also ranked in the top 20 countries by total medal count in the 2016 Summer Olympics. 

Our team will develop multiple regression models using predictors like GDP per Capita, Population, whether a country is a host country, and whether a country is a former soviet or communist state. We will use these factors to predict medal count, and examine how these each of these factors influences medal count. We will build the model on countries’ total medal count for the 1996, 2004, 2008, and 2012 Olympics, and then project the model onto the 2016 Olympics to understand the accuracy of the model’s predictions. 

# Methods and Materials

## Data 

### Dependent Variable
We model on the total number of medal counts, by participating country and year during which a Summer Olympics occurred. The dependent variable data come from a website called $www.medalspercapita.com$. For any given Summer Olympics, this website only lists the 80 - 90 countries that have won at least one medal, out of the 200 or so nations that participate in each summer Olympics. 

Table 1 and Figure 1 both illustrate that the medal counts exhibit right-skewed distribution. Among countries that have won at least one medal, the median medal count is 5, while the mean medal count is 12. The skewed distribution suggests the need for a log transformation (in the case of a linear model), which can also ensure that the predictions are positive numbers. Moreover, given we are modeling on count data, where large counts rarely occur, a Poisson model may be more appropriate than linear regression.

### Predictor Variables
Based on existing literature (Bernard and Busse 2006, Goldman Sachs 2016, Bian 2005), potentially significant predictors of medal count include size of population, GDP per capita, whether or not a country has hosted or will host a summer Olympics, and whether or not a country is or was a command economy.

$X_1: Population$: This variable indicates population of people in the country in the associated year. Figure 2 shows a histogram of the population data. The left chart illustrates the right-skewed distribution of the original data (with China and India representing the far right). The right chart shows that applying a natural log transformation reduces the skewness and the influence of extreme X variable values on the model. 

$X_2: GDP/Capita$: This variable indicates GDP per capita in the associated year. These data show a similar distribution to the population variable, so we also applied the natural log transformation.

$X_3: Host (1/0)$: This is a binary predictor variable with value equal to 1 if a country has hosted a summer Olympics in the 8 years prior to the Olympics in consideration, or will host in the next 8 years. For example, Greece, which hosted the 2004 Olympics, will have value = 1 for the 1996, 2000, 2004, 2008, and 2012 Olympics. 25 observations are classified as a host by this measure. 

$X_4: Command Economy  (1/0)$: This binary predictor variable indicates whether the country was once a member of the Soviet Union or Yugoslavia, or ruled by a Communist party. We assembled a list of formerly or currently Soviet, Yugoslavian, or Communist countries using $www.worldatlast.com$, $Wikepedia$'s list of communist parties, and $www.sporcle.com$. 111 data points are classified as former Soviet Union or Communist.

We generate a correlation matrix (Table 2) and paired scatterplot (Figure 3) to illustrate the relationships between the variables, especially any multicollinearity. 

The scatter plot matrix in Figure 3 shows positive correlation between count of medals and population size. We do not observe strong linear relationship between medal count and GDP per capita, whether or not a country has hosted or will host, and whether a country used to be part of a Command Economy. The correlation matrix corroborates the finding that population size has the strongest linear correlation with medal count (correlation = 0.48), and Command Economy (Y/N) has the weakest linear correlation (correlation = 0.09).

This correlation matrix in Table 3 also suggests that collinearity between variables will not be a significant problem. The most significant correlation between predictor variables is between the log of the GDP per capita and the indicator of Communism or Soviet Union inclusion variable. However, the correlation coefficient is only -0.2989. This suggests that multicollinearity should not be much of an issue.


```{r, include = F, echo=FALSE}
library(knitr)
summary(base$count)
```


```{r medal_count_hist, include = F, echo=FALSE}
hist(base$count)
```


```{r count_2008_hist, echo=FALSE, include = F}
hist(base[which(base$year == c("2008")),c("count")])
```


```{r, echo=FALSE, include = F}
summary(base$gdp)
```

```{r, echo=FALSE, include = F}
summary(base$pop)
```

```{r, echo=FALSE, include = F}
sum(base$comm_soviet)
nrow(base)-sum(base$comm_soviet)
```

```{r, echo=FALSE, include = F}
sum(base$host)
```


```{r pop_hists, echo=FALSE, include = F}
par(mfrow=c(1,2))
#Histogram Population
hist(base$pop,main = "Untransformed",xlab = "Population")
#Histogram log(Population)
hist(log(base$pop),main = "Transformed",xlab = "log(Population)")
```


```{r log_gdp_box, echo=FALSE, include = F}
#Log(GDP)
boxplot(log(base$gdp),ylab = "log(GDP)")
```


```{r log_pop_box, echo=FALSE, include = F}
#log(Population)
boxplot(log(base$pop),ylab = "log(Population)")
```


```{r scatter_mat, echo=FALSE, include = F}
pairs(Olympic[,c(2,4,5,6,7)])
```


```{r corr_mat, include = F, echo=FALSE}
kable(cor(Olympic[,c(2,4,5,6,7)]))
```

## Model Building and Selection

We will consider two types of models: a linear model and a Poisson model, given the count nature of the data.

### Linear Model

```{r, include=FALSE}
library(leaps)
#CP
olympic.leapCP <- leaps(y=log(Olympic_v2$count), x=Olympic_v2[,4:7])
#R2a
olympic.leapR2a <- leaps(y=log(Olympic_v2$count), x=Olympic_v2[,4:7], method = 'adjr2')
  ### Code for AIC
xList <- names(Olympic_v2)[4:7]
  #### Remove the last row that has all False's
vec <- olympic.leapCP$which
  ### Name the columns in the grid
names(vec) <- paste("X", 1:4, sep="")
  #### Build matrix of formula for every row
allModelsList <- apply(vec, 1, function(x) as.formula(
  paste(c("count ~ 1", xList[x]), collapse = "+")))
  ### Calculate the coefficients for all 16 models
allModelsResults.lm <- lapply(allModelsList, 
                           function(x) lm(x, data=Olympic_v2))
```


According to the selected model diagnostics shown in Table 3, the model with the smallest $C_p$ statistic, largest adjusted $R^2$ value, smallest AIC and smallest PRESS value is the model that includes all four predictor variables. We constructed a linear model (shown below), using the natural log to transform the count data. We decided to transform the count data to get the response variable to look more normally distributed so that it would follow the linear regression assumption that the response variable needs to be approximately normally distributed.

```{r, echo = F}
olympic.lmfinal <- lm(log_count ~ log_pop + log_gdp_per_cap + host + comm_soviet, data = Olympic_v2)
```

$$X_1 = \text{ln(population)}$$
$$X_2 = \text{ln(gdp/capita)}$$
$$X_3 = \text{host}$$
$$X_4 = \text{Soviet Country or Communist}$$
$$Y = \text{ln(Count)}$$
$$\hat{Y} = -9.63058+0.44275X_1+0.40830X_2+0.86726X_3+1.03281X_4$$

```{r, echo=FALSE, include = F}
par(mfrow=c(2,2))
plot(olympic.lmfinal)
```

According to the Normal Q-Q plot (Figure X), it is reasonable to assume the residuals follow a normal distribution. However, the Residuals vs Fitted plot indicates possible heteroskedasticity or non-constant variance of the errors. The Breusch-Pagan test will help us determine if heteroskedasticity is affecting the model.


Assuming $Var(\epsilon_i)=\sigma^2_i$ such that $\text{log}_e\sigma_i^2=\gamma_0+\gamma_1X_i$:

$$H_0:\gamma_1,\text{vs. } H_a:\gamma_1\neq0$$
At significance level $\alpha = 0.05$, if the p-value of the Breusch-Pagan test is less than $\alpha$ then we reject $H_0$ and conclude $H_a$, otherwise we fail to reject $H_0$. Rejecting $H_0$ in favor of $H_a$ means that we conclude that the variance is non-constant.

```{r, include=FALSE}
library(lmtest)
bptest(log_count ~ log_pop + log_gdp_per_cap + host + comm_soviet,data = Olympic_v2,studentize = FALSE)
```
The p-value $= 0.001587<\alpha$, therefore we conclude that our variance is not constant.

$$H_0: \text{Sample comes from a N(}\mu,\sigma^2\text{) distribution}$$
$$H_a: \text{Sample does not come from a N(}\mu,\sigma^2\text{) distribution}$$
At significance level $\alpha = 0.05$, if the p-value is less than $\alpha$ then we accept $H_a$ and reject $H_0$, otherwise we fail to reject $H_0$.

```{r, include=FALSE}
library(nortest)
```
```{r, include = F}
lillie.test(olympic.lmfinal$residuals)
```
The p-value$=0.2332>\alpha$, thus we fail to reject $H_0$. Therefore, it is reasonable to assume that the error terms are distributed normally.

We attempt to correct for non-constant variance and outliers by using robust linear regression, with Huber and Bisquare weights. As shown in table 6, the coefficients generated through robust linear regression, using Bisquare weights, fall within +/- 5% of the corresponding OLS regressions. The robust regression’s standard errors are slightly larger than those of the OLS regression. We find similar results when using Huber weights. Re-running the Breusch-Pagan test results in a p-value of 0.002, which means we would still reject the null hypothesis of homoskedasticity at $\alpha$ = 0.05 level, and conclude that the robust regression still exhibits non-constant variance.


#### Influential Cases
Appendix C summarizes the influential cases in our model. We can see from the list that highly populous countries, such as the United States, China, and India are influential on our model. Additionally, many of the influential cases are identified as being host nations. We wanted to identify these influential cases for the sake of full analysis, but we are choosing to not delete them from the model because they are important data points. It would not be feasible to delete 37 points and high populous countries are important to the analysis.


### Generalized Linear Model

The first choice for a glm is typically a Poisson model, which may provide a reasonable model for these data. This generalized model was created with the same variables as the linear model; population, GDP per capita, the host dummy variable, and the communist/soviet dummy variable. 

$$\text{ln}(E(Y_i|X_i)) = \text{ln}(\lambda_i) = \beta_0+\beta_1X_1+\beta_2X_2+\beta_3X_3+\beta_4X_4$$
$$\text{ln}(E(Y_i|X_i)) = \text{ln}(\lambda_i) = -11.28882+0.50479X_1+0.52117X_2+0.31070X_3+1.02332X_4$$


Like the linear model, the population and GDP per capita were log-transformed, but in this model it is unnecessary to transform the medal count. The full poisson model showed highly significant parameters, but the dispersion of this model was much greater than 1 (disp. = 6.621). This is a violation of the assumptions of a Poisson regression model, so a negative binomial model would likely provide a better fit for these data. 

```{r, comment = NA, include=F}
Olympic.pois<-glm(count~log_pop + log_gdp_per_cap + host + comm_soviet, data = Olympic_v2, family = poisson)
P__disp(Olympic.pois)
```

```{r negative binomial, echo = F}
library(MASS)
olympic.nb <- glm.nb(count~log_pop + log_gdp_per_cap + host + comm_soviet, data = Olympic_v2)
```

```{r nb leaps, echo = F}
library(leaps)
olympic.nb_leap <- leaps(y=Olympic_v2$count, x=Olympic_v2[,4:7])
Cp.nb<-round(olympic.nb_leap$Cp, 2)
which<-olympic.nb_leap$which
rownames(which) <-NULL
colnames(which)<-c('Pop', 'GDP/C', 'Host', 'Soviet')
```

A negative binomial regression model assumes that dispersion is greater than 1, which is consistent with these data. Therefore, it allows for more accurate tests of the parameters. Among the negative binomial models, the best model again proved to be the full model, after a comparison of AIC between all subsets of variables (Table X).

$$\text{ln}(E(Y_i|X_i)) = \text{ln}(\lambda_i) = \beta_0+\beta_1X_1+\beta_2X_2+\beta_3X_3+\beta_4X_4$$
$$\text{ln}(E(Y_i|X_i)) = \text{ln}(\lambda_i) = -10.16577+0.49848X_1+0.40239X_2+0.69267X_3+1.03376X_4$$

Independence among observations constitutes a key assumption for the Poisson and negative binomial regressions. Since our model uses panel data, observations over time for the same country will exhibit serial autocorrelation, thereby violating the independence assumption. Moreover, the medal counts among countries within a given year are not completely independent, because of the fixed total number of medals awarded in a single Olympic year.

To address the above non-independence, we tried adding year and country fixed effects to the negative binomial regression. The models take the form: 

$$\text{ln}(Y_it) = \beta_0+\beta_1X_1it+\beta_2X_2it+\beta_3X_3it+\beta_4X_4it+d_t$$

$$\text{ln}(Y_it) = \beta_0+\beta_1X_1it+\beta_2X_2it+\beta_3X_3it+\beta_4X_4it+v_i$$

where $d_i$ and $v_i$ represent dummies for year $t$ and country $i$, respectively. The year fixed effect accounts for changing number of sports and number of country participants. The country fixed effect accounts for unobserved factors that vary little over time, such as a country’s investment in national sports teams, cultural attitude toward the Olympics, etc.


```{r weird algorithm thing, echo = F}
xList <- names(Olympic_v2)[4:7]
vec <- olympic.nb_leap$which
#Name the columns in the grid
names(vec) <- paste("X", 1:4, sep="")
#Build matrix of formula for every row
allModelsList <- apply(vec, 1, function(x) as.formula(
  paste(c("count ~ 1", xList[x]), collapse = "+")))
#Calculate the coefficients for all 16 models
allModelsResults <- lapply(allModelsList, 
                           function(x) glm.nb(x, data=Olympic_v2))
AIC.nb<-matrix(unlist(lapply(allModelsResults, function(x) round(extractAIC(x),2))), ncol = 2, byrow = T)[,2]
library(knitr)
```

```{r, echo = F, include = F}
#2016 Data
base.2016 = base[which(base$year==2016),]
attach(base.2016)
base.2016 = data.frame(country,count,year,log_pop=log(pop),log_gdp_per_cap = log(gdp/pop),host,comm_soviet)


#Linear Fitted
fitted.lm = -9.63058+0.40830*base.2016$log_gdp_per_cap+0.44275*base.2016$log_pop+0.86726*base.2016$host+1.03281*base.2016$comm_soviet
#olympic.lmfinal  
  
  


#Prediction intervals: Linear Model
nrow(base.2016)-5
t=qt(1-0.05/2,76)
mse.lm = 0.751
X = as.matrix(cbind(rep(1,nrow(Olympic_v2)),Olympic_v2$log_gdp_per_cap,Olympic_v2$log_pop,Olympic_v2$host,Olympic_v2$comm_soviet))

spred = c()
for (i in 1:nrow(base.2016)){
  xh = as.matrix(cbind(1,base.2016$log_gdp_per_cap[i],base.2016$log_pop[i],base.2016$host[i],base.2016$comm_soviet[i]))
  s2 = mse.lm*(1+xh%*%solve(t(X)%*%X)%*%t(xh))
  spred = c(spred,sqrt(s2))
}

lower.pred = fitted.lm - qt(1-0.05/2,76)*spred
upper.pred = fitted.lm + qt(1-0.05/2,76)*spred

forecast.lm = cbind(log(base.2016$count),lower.pred,upper.pred)
ininterval.lm = cbind(forecast.lm[,2]<=forecast.lm[,1] & forecast.lm[,3]>=forecast.lm[,1])
length(which(ininterval.lm))

#NB Method 2 (works!)
library(tidyverse)
library(ciTools)
library(MASS) 

set.seed(20181215)

base.2016 = base[which(base$year==2016),]
attach(base.2016)
base.2016 = data.frame(country,count,year,log_pop=log(pop),log_gdp_per_cap = log(gdp/pop),host,comm_soviet)

newData <- data.frame(base.2016[,c(2,4,5,6,7)])
train_data <- Olympic_v2[,3:7]

#Generate prediction intervals
olympic.nb = glm.nb(count ~ log_pop + log_gdp_per_cap + host + comm_soviet,data=train_data)

#add_pi comes from the library ciTools
olympic.nb_pint <- add_pi(tb=newData,fit=olympic.nb, names=c("lpb", "upb"), alpha=0.1, nSims=20000)


olympic.nb_pint %>%
  mutate(inside=(count >lpb & count<upb))->preds.nb

summary(preds.nb)


####finding MSEs
preds<-data.frame(matrix(cbind(base.2016$count, preds.nb$pred, exp(fitted.lm)), ncol = 3))

colnames(preds)<-c('Actual', 'Prediction.nb', 'Prediction.lm')

mse.nb<-mean((preds$Actual-preds$Prediction.nb)^2)
mse.lm<-mean((preds$Actual-preds$Prediction.lm)^2)
```


# Results 

## Comparison of Models

Table 6 compares the coefficients across different model specifications. We observe the following: 

- Compared to the OLS linear model, the robust linear model produces slightly larger standard errors, but similar coefficient magnitudes. This finding suggests that outliers do not substantially influence the OLS linear model fit.

- As expected from the dependent variable's over-dispersion, the Poisson regression underestimates the standard error, compared to the other 4 model specifications.

- Negative binomial produces similar coefficient and standard error estimates as OLS and robust linear regressions.

Figure 5 compares the Actual medal count values vs. the values fit by the OLS linear regression and negative binomial regressions. The blue dots plot the predicted vs. actual values for all observations. The red line indicates perfect fit. We observe that the negative binomial regression appears to have better fit of the data.

Interestingly, table 6 shows that the OLS linear regression has better model fit, because it has lower AIC and MSE.

## 2016 Out-of-sample Projection:

As part of the data collection process, information for the year 2016 was also researched, but left out of the original analysis. Therefore, because the data was not part of the training set, we can use it as a testing set. The medal count data for 2016 is similarly distributed to the overall training data, so testing on it is a feasible plan.

To determine the accuracy of each of our models we determined 95% prediction intervals for each of the 81 points in the 2016 medal count data. Then we calculated the ratio of data points that had their actual counts within their respective prediction intervals to total number of data points. For our estimated linear regression function, 
$$\hat{Y} = -9.63058+0.44275X_1+0.40830X_2+0.86726X_3+1.03281X_4$$
74 out of 81 points had medal counts within their respective 95% prediction intervals. 

The same analysis on the negative binomial model showed that a similar number of the 95% predictions intervals for 2016 fell around their observed intervals.

$$\text{ln}(E(Y_i|X_i)) = \text{ln}(\lambda_i) = -10.16577+0.49848X_1+0.40239X_2+0.69267X_3+1.03376X_4$$

# Discussion and Conclusions

\newpage
# Bibliography

\newpage
# Appendix A
```{r, echo = F}
options(scipen = 999)

kable(rbind('Count'=summary(Olympic_v2$count), 'Population'=summary(exp(Olympic_v2$log_pop)), 'GDP/Cap'=summary(exp(Olympic_v2$log_gdp_per_cap))), caption = 'Summary of Numerical Variables')
```

```{r, echo=FALSE, fig.pos='h', out.extra = '', fig.cap='Distribution of Count', fig.height=3}
hist(Olympic_v2$count, lwd = 4, xlab = '', main = '')
```

```{r, echo=FALSE, fig.pos='h', out.extra = '', fig.cap='Histogram of the Population Variables'}
par(mfrow=c(1,2))
#Histogram Population
hist(base$pop,main = "Untransformed",xlab = "Population")
#Histogram log(Population)
hist(log(base$pop),main = "Transformed",xlab = "log(Population)")
```

```{r, echo=FALSE, fig.pos='h', out.extra = '', fig.cap='Scatter Matrix'}
plot(Olympic_v2[,c(3,4,5,6,7)])
```

```{r, echo = F}
kable(cor(Olympic_v2[,c(3,4,5,6,7)]), caption = 'Correlation Matrix')
```

```{r linear_diags, echo = F, include = F}
#PRESS (Non-Mac)
library(qpcR)
olympic.lm = PRESS(lm(log_count~log_pop+log_gdp_per_cap+host+comm_soviet, data = Olympic_v2))
olympic.lmX1 = PRESS(lm(log_count~log_pop, data = Olympic_v2))
olympic.lmX2 = PRESS(lm(log_count~log_gdp_per_cap, data = Olympic_v2))
olympic.lmX3 = PRESS(lm(log_count~host, data = Olympic_v2))
olympic.lmX4 = PRESS(lm(log_count~comm_soviet, data = Olympic_v2))
olympic.lmX1X2 = PRESS(lm(log_count~log_pop+log_gdp_per_cap, data = Olympic_v2))
olympic.lmX1X3 = PRESS(lm(log_count~log_gdp_per_cap+host, data = Olympic_v2))
olympic.lmX1X4 = PRESS(lm(log_count~log_pop+comm_soviet, data = Olympic_v2))
olympic.lmX2X3 = PRESS(lm(log_count~log_gdp_per_cap+host, data = Olympic_v2))
olympic.lmX2X4 = PRESS(lm(log_count~log_gdp_per_cap+comm_soviet, data = Olympic_v2))
olympic.lmX3X4 = PRESS(lm(log_count~host+comm_soviet, data = Olympic_v2))
olympic.lmX1X2X3 = PRESS(lm(log_count~log_pop+log_gdp_per_cap+host, data = Olympic_v2))
olympic.lmX1X2X4 = PRESS(lm(log_count~log_pop+log_gdp_per_cap+comm_soviet, data = Olympic_v2))
olympic.lmX2X3X4 = PRESS(lm(log_count~log_gdp_per_cap+host+comm_soviet, data = Olympic_v2))
olympic.lmX1X3X4 = PRESS(lm(log_count~log_pop+host+comm_soviet, data = Olympic_v2))
olympic.lm_press <- rbind(olympic.lmX1$stat,
                          olympic.lmX3$stat,
                          olympic.lmX2$stat,
                          olympic.lmX4$stat,
                          olympic.lmX1X3$stat,
                          olympic.lmX1X2$stat,
                          olympic.lmX1X4$stat,
                          olympic.lmX2X3$stat,
                          olympic.lmX3X4$stat,
                          olympic.lmX2X4$stat,
                          olympic.lmX1X2X3$stat,
                          olympic.lmX1X2X4$stat,
                          olympic.lmX1X3X4$stat,
                          olympic.lmX2X3X4$stat,
                          olympic.lm$stat)
#Summary
Diagnostics = cbind(olympic.leapCP$which, Cp=round(olympic.leapCP$Cp,2), aR2=round(olympic.leapR2a$adjr2,2),
      AIC=matrix(unlist(lapply(allModelsResults.lm, function(x) round(extractAIC(x),2))), ncol=2, byrow=TRUE)[,2], PRESS = olympic.lm_press)
#PRESS wasn't showing as column name
colnames(Diagnostics) = c("1","2","3","4","Cp","aR2","AIC","PRESS")
```

```{r, echo=FALSE, fig.pos='h', out.extra = '', fig.cap='Exploratory Linear Model Plots'}
par(mfrow=c(2,2))
plot(olympic.lmfinal)
```

\newpage

```{r, echo = F}
kable(Diagnostics, caption = 'Model Selection for Linear Model')
```

\newpage

```{r, echo = F}
kable(cbind(which, Parameters = olympic.nb_leap$size, Cp.nb, AIC.nb), caption = 'Model Selection Diagnostics for a Negative Binomial Model', format.args = list(justify = 'centre'))
```

\newpage

```{r AIC_comp, echo = F}
df_20<-data.frame(matrix(c(2008.82, 442.44, 279.47, 2319.23,  480.74, 675.54), nrow = 2, byrow = T))
colnames(df_20)<-c('AIC', 'MSE', 'MSE (out of sample)')
rownames(df_20)<-c('Linear', 'Negative Binomial')
kable(df_20, caption = 'Linear vs. GLM Model Comparison (Absolute Scale)')
```

\newpage

```{r pred_vs_act, echo = F, echo=FALSE, fig.pos='h', out.extra = '', fig.cap='Comparison of Predicted vs. Actual'}
par(mfrow=c(1,2))
plot(x=Olympic_v2$count, y = exp(olympic.lmfinal$fitted.values), col='blue', pch=20, xlab='Actual',
     ylab='Predicted', main='OLS Linear Regression')
abline(a=0,b=1, col='red')
plot(x=Olympic_v2$count, y = olympic.nb$fitted.values, col='blue', pch=20, xlab='Actual',
     ylab='Predicted', main='Negative Binomial Regression')
abline(a=0,b=1, col='red')
```

\newpage

```{r intervals, echo = F, echo=FALSE, fig.pos='h', out.extra = '', fig.cap='Linear Prediction intervals vs actual count.'}

plot(1:81, preds.nb$count, col = 'red', pch = 20, ylim = c(0, 150), xlab = '', ylab = 'Interval (Blue) Vs. Actual (Red)')
points(1:81, exp(forecast.lm[,2]), pch = 20, col = 'blue')
points(1:81, exp(forecast.lm[,3]), pch = 20, col = 'blue')
```

```{r, echo = F, echo=FALSE, fig.pos='h', out.extra = '', fig.cap='Negative Binomial Prediction intervals vs actual count.'}
plot(1:81, preds.nb$count, col = 'red', pch = 20, ylim = c(0, 150), xlab = '', ylab = 'Interval (Blue) Vs. Actual (Red)')
points(1:81, preds.nb$lpb, pch = 20, col = 'blue')
points(1:81, preds.nb$upb, pch = 20, col = 'blue')
```

 \newpage
 
```{r coeff, echo = F}
df_133<-data.frame(matrix(c(
'-9.63 (0.638)', '-10.04 (0.67)','-11.23 (0.254)','-10.17 (0.647)','-10.57 (0.641)',
'0.408 (0.032)','0.412 (0.034)','0.521 (0.014)','0.402 (0.029)','0.452 (0.033)',
'0.443 (0.029)','0.464 (0.031)','0.505 (0.010)','0.498 (0.032)','0.506 (0.028)',
'0.867 (0.190)','0.829 (0.199)','0.311 (0.042)','0.693 (0.159)','0.608 (0.153)',
'1.033 (0.105)','1.04 (0.110)','1.02 (0.037)','1.03 (0.098)','1.08 (0.097)'
), ncol = 5, byrow = T))
colnames(df_133)<-c(
'Linear',
'Robust (Bisquare)',
'Poisson',
'Neg Binom',
'Neg Binom (fixed effects')
rownames(df_133)<-c('Intercept','log(GDP/Cap)','log(Pop)','Host','Soviet/Comm')
kable(df_133, caption = 'Coefficient Comparison')
```

\newpage
\newpage

# Appendix B
```{r, ref.label=knitr::all_labels(),echo=TRUE,eval=FALSE}
```

\newpage

# Appendix C: Influential Cases
```{r, echo = F, include = T, comment = NA}
#Influential cases
olympic.lm_inf=influence.measures(olympic.lmfinal)$is.inf
idx=which(apply(olympic.lm_inf,1,any))
#Influential Cases
kable(Olympic[idx,])
```

\newpage

```{r, echo = F, include = T, comment = NA}
#Inluential Cases by Test
kable(olympic.lm_inf[idx,])
```
