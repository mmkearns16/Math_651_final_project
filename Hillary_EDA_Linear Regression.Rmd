Introduction:
(Projective Objectives)
(Scientific QUestions of Interst)



**Methods and Materials:**\
\
Brief Description of the Problem:
The purpose of this reasearch is to determine whether there is a predictive relationship between popluation, GDP per capita, being a host nation, or at one point being a Communist nation or a member of the Soviet Union and number of medals won at the Olympics in the associated year by country. 

Sources:
```{r, include=FALSE}
#Upload data
base = read.csv("~/Downloads/base_data.csv")
head(base)

#Get years 1996, 2000, 2004, 2008, 2012
base.total = base[which(base$year!=2016),]

#Create GDP/Capita
attach(base.total)
base.total = data.frame(country,count,year,pop,gdp_per_cap = gdp/pop,host,comm_soviet)
```





Brief Description of Data:\
\
Response Variable:\
$Y$: Total number of medals won by a country in a year.\
```{r, echo=FALSE}
summary(base.total$count)
```
As we can see, the average number of medals won by a country in a year is 11.79 medals and the minimum number of medals is one. This is meaningful because this means we are only assessing countries that have won at least one medal in at least one of the years we are analyzing. \
\
Below we see that the medal count is distributed exponentially, which could indicate a need to transform the response variable if we need to fit a linear regression model.
```{r, echo=FALSE}
hist(base$count)
```

Predictor Variables:\
$X_1$: This variable indicates population of people in the country in the associated year. Below, we can see a histogram of the population data. On the left, is the original distribution of the data points and on the right, we've transformed the data to look more normally distributed.
```{r, echo=FALSE}
par(mfrow=c(1,2))
#Histogram Population
hist(base.totalc$pop,main = "Untransformed",xlab = "Population")
#Histogram log(Population)
hist(log(base.totalc$pop),main = "Transformed",xlab = "log(Population)")
```

$X_2$: This variable indicates GDP per capita in the associated year. Below, we can see a histogram of the GDP per capita data. On the left, is the original distribution of the data points and on the right, we've transformed the data to look more normally distributed. \
```{r, echo=FALSE}
par(mfrow=c(1,2))
#Histogram GDP
hist(base.total$gdp_per_cap,main = "Untransformed",xlab = "GDP per Capita")
#Histogram log(GDP)
hist(log(base.total$gdp_per_cap),main = "Transformed",xlab = "log(GDP per Capita)")
```


$X_3$: This binary predictor variable indicates with a 1 if a country hosted the Olympics within the previous 8 years, whether the country is hosting the Olympics in that year, or if the country is hosting within 8 years in the future. Of all the data points, 25 are classified as host within 8 years prior, current host or future host within 8 years. This makes sense because we are considering 5 years in our training data and each year has five countries that can be classified by this predictor variable.\
$X_4$: This binary predictor variable indicates whether the country was once a member of the Soviet Union or if they were indicated as ever being a Communist country. From __________ we aggregated a binary predictor variable that identifies countries that were once members of the Soviet Union or at one time classified as communist countries. 111 data points are classified as former Soviet Union or Communist.(INSERT SOURCE AGAIN???)\
\
In addition to the predictors and response variable, each data point has an associated country and year.\
\

Graphical Analysis of Variables:
Histograms of GDP / capita:

\
NOT SURE HOW TO INTRODUCE THESE:

\
Boxplot of $\text{log}(\text{GDP})$:
```{r, echo=FALSE}
#Log(GDP)
boxplot(log(base.totalc$gdp),ylab = "log(GDP)")
```
\
Boxplot of $\text{log}(\text{Population})$:
```{r, echo=FALSE}
#log(Population)
boxplot(log(base.totalc$pop),ylab = "log(Population)")
```

```{r}
#Create Olympic dataframe with logs
Olympic = data.frame(year,country,count,log_pop = log(pop),log_gdp_per_cap = log(gdp/pop),host,comm_soviet)
```

INSERT WHY WE DECIDED TO GO WITH LOG OF VARIABLES


To properly determine an ideal model for the data, we need to address the relationships between variables. We can do this be analyzing both the scatterplot matrix of variables and the correlation matrix.
```{r, echo=FALSE}
pairs(Olympic[,3:7])
```
\
The scatterplot matrix does not obviously show us many relationships between the predictor variables and their effect on the response variable. While there might be a relationship between the log of the population and the medal count, it is difficult to determine from the plot if this is a linear relationship. Additional information can be collected from the correlation matrix below.\
```{r, echo=FALSE}
cor(Olympic[,3:7])
```
This correlation matrix suggests that collinearity between variables will not be a significant issue. The most significant correlation between predictor variables is between the log of the GDP per capita and the indicator of Communism or Soviet Union inclusion variable. However, the correlation coefficient is only -0.2989.\
\
WRITE WHY WE GO WITH LOG OF COUNT!
```{r, include=FALSE}
Olympic_v2 = data.frame(year,country,log_count = log(count),log_pop,log_gdp_per_cap,host,comm_soviet)
attach(Olympic_v2)
```

Model 1 Considered: Multiple Linear Regression with transformed variables\
\
Prior to the creation of the multiple linear regression model, we needed to run diagonstic tests to determine an ideal selection of the predictor variables. We assessed the Mallow's $C_p$ statistic, the adjusted $R^2$, the AIC and the PRESS diagnostic values below.\
```{r, include=FALSE}
library(leaps)
#CP
olympic.leapCP <- leaps(y=log_count, x=Olympic_v2[,4:7])
#R2a
olympic.leapR2a <- leaps(y=log_count, x=Olympic_v2[,4:7], method = 'adjr2')

  ### Code for AIC
xList <- names(Olympic_v2)[4:7]
  #### Remove the last row that has all False's
vec <- olympic.leapCP$which
  ### Name the columns in the grid
names(vec) <- paste("X", 1:4, sep="")
  #### Build matrix of formula for every row
allModelsList <- apply(vec, 1, function(x) as.formula(
  paste(c("count ~ 1", xList[x]), collapse = "+")))
  ### Calculate the coefficients for all 16 models
allModelsResults <- lapply(allModelsList, 
                           function(x) lm(x, data=Olympic_v2))

```

```{r, eval=FALSE, include=FALSE}
#PRESS (Non-Mac)
library(qpcR)
olympic.lm = PRESS(lm(log_count~log_pop+log_gdp_per_cap+host+comm_soviet))
olympic.lmX1 = PRESS(lm(log_count~log_pop))
olympic.lmX2 = PRESS(lm(log_count~log_gdp_per_cap))
olympic.lmX3 = PRESS(lm(log_count~host))
olympic.lmX4 = PRESS(lm(log_count~comm_soviet))
olympic.lmX1X2 = PRESS(lm(log_count~log_pop+log_gdp_per_cap))
olympic.lmX1X3 = PRESS(lm(log_count~log_gdp_per_cap+host))
olympic.lmX1X4 = PRESS(lm(log_count~log_pop+comm_soviet))
olympic.lmX2X3 = PRESS(lm(log_count~log_gdp_per_cap+host))
olympic.lmX2X4 = PRESS(lm(log_count~log_gdp_per_cap+comm_soviet))
olympic.lmX3X4 = PRESS(lm(log_count~host+comm_soviet))
olympic.lmX1X2X3 = PRESS(lm(log_count~log_pop+log_gdp_per_cap+host))
olympic.lmX1X2X4 = PRESS(lm(log_count~log_pop+log_gdp_per_cap+comm_soviet))
olympic.lmX2X3X4 = PRESS(lm(log_count~log_gdp_per_cap+host+comm_soviet))
olympic.lmX1X3X4 = PRESS(lm(log_count~log_pop+host+comm_soviet))

olympic.lm_press <- rbind(olympic.lmX1$stat,
                          olympic.lmX3$stat,
                          olympic.lmX2$stat,
                          olympic.lmX4$stat,
                          olympic.lmX1X3$stat,
                          olympic.lmX1X2$stat,
                          olympic.lmX1X4$stat,
                          olympic.lmX2X3$stat,
                          olympic.lmX3X4$stat,
                          olympic.lmX2X4$stat,
                          olympic.lmX1X2X3$stat,
                          olympic.lmX1X2X4$stat,
                          olympic.lmX1X3X4$stat,
                          olympic.lmX2X3X4$stat,
                          olympic.lm$stat)
```

```{r, echo=FALSE}
#PRESS (Mac)
library(MPV)
olympic.lm = PRESS(lm(log_count~log_pop+log_gdp_per_cap+host+comm_soviet))
olympic.lmX1 = PRESS(lm(log_count~log_pop))
olympic.lmX2 = PRESS(lm(log_count~log_gdp_per_cap))
olympic.lmX3 = PRESS(lm(log_count~host))
olympic.lmX4 = PRESS(lm(log_count~comm_soviet))
olympic.lmX1X2 = PRESS(lm(log_count~log_pop+log_gdp_per_cap))
olympic.lmX1X3 = PRESS(lm(log_count~log_gdp_per_cap+host))
olympic.lmX1X4 = PRESS(lm(log_count~log_pop+comm_soviet))
olympic.lmX2X3 = PRESS(lm(log_count~log_gdp_per_cap+host))
olympic.lmX2X4 = PRESS(lm(log_count~log_gdp_per_cap+comm_soviet))
olympic.lmX3X4 = PRESS(lm(log_count~host+comm_soviet))
olympic.lmX1X2X3 = PRESS(lm(log_count~log_pop+log_gdp_per_cap+host))
olympic.lmX1X2X4 = PRESS(lm(log_count~log_pop+log_gdp_per_cap+comm_soviet))
olympic.lmX2X3X4 = PRESS(lm(log_count~log_gdp_per_cap+host+comm_soviet))
olympic.lmX1X3X4 = PRESS(lm(log_count~log_pop+host+comm_soviet))

olympic.lm_press <- rbind(olympic.lmX1,
                          olympic.lmX3,
                          olympic.lmX2,
                          olympic.lmX4,
                          olympic.lmX1X3,
                          olympic.lmX1X2,
                          olympic.lmX1X4,
                          olympic.lmX2X3,
                          olympic.lmX3X4,
                          olympic.lmX2X4,
                          olympic.lmX1X2X3,
                          olympic.lmX1X2X4,
                          olympic.lmX1X3X4,
                          olympic.lmX2X3X4,
                          olympic.lm)
#Summary
Diagnostics = cbind(olympic.leapCP$which, Cp=round(olympic.leapCP$Cp,2), aR2=round(olympic.leapR2a$adjr2,2),
      AIC=matrix(unlist(lapply(allModelsResults, function(x) round(extractAIC(x),2))), ncol=2, byrow=TRUE)[,2],
      PRESS = olympic.lm_press)
#PRESS wasn't showing as column name
colnames(Diagnostics) = c("1","2","3","4","Cp","aR2","AIC","PRESS")
Diagnostics
```
According to the selected model diagnostics, the model with the smallest $C_p$ statistic, largest adjusted $R^2$ value, smallest AIC and smallest PRESS value is the model that includes all four predictor variables.\
\
Build the Regression model:
```{r}
olympic.lmfinal <- lm(log_count ~ log_pop + log_gdp_per_cap + host + comm_soviet)
summary(olympic.lmfinal)
```
Estimated Regression Function:
$$X_1 = \text{log(population)}$$
$$X_2 = \text{log(gdp/capita)}$$
$$X_3 = \text{host}$$
$$X_4 = \text{Soviet Country or Communist}$$
$$\hat{Y} = -9.63058+0.44275X_1+0.40830X_2+0.86726X_3+1.03281X_4$$
Residual analysis:
```{r, echo=FALSE}
par(mfrow=c(2,2))
plot(olympic.lmfinal)
```
Assumptions:
According to the Normal Q-Q plot, it is reasonable to assume the residuals follow a normal distribution. Hoever, the Residuals vs Fitted plot indicates possible heteroskedasticity or non-constant variance of the errors. The Breusch-Pagan test will help us determine if heteroskedasticity is affecting the model.

Breusch Pagan Test: Assuming $Var(\epsilon_i)=\sigma^2_i$ such that $\text{log}_e\sigma_i^2=\gamma_0+\gamma_1X_i$:
Alternatives:
$$H_0:\gamma_1,\text{vs. } H_a:\gamma_1\neq0$$
Decision Rule: At significance level $\alpha = 0.05$, if the p-value of the Breusch-Pagan test is less than $\alpha$ then we reject $H_0$ and accept $H_a$, otherwise we fail to reject $H_0$. Accepting $H_a$ means we accept that the variance is non-constant.
```{r, include=FALSE}
library(lmtest)
```
```{r}
bptest(log_count ~ log_pop + log_gdp_per_cap + host + comm_soviet,data = Olympic_v2,studentize = FALSE)
```
The p-value $= 0.001587<\alpha$, therefore we accept the alternative hypothesis that our variance is not constant.

Test for normality (Lilliefors Test):\
Alternatives:
$$H_0: \text{Sample comes from a N(}\mu,\sigma^2\text{) distribution}$$
$$H_a: \text{Sample does not come from a N(}\mu,\sigma^2\text{) distribution}$$
Decision Rule: At signifcance level $\alpha = 0.05$, if the p-value is less than $\alpha$ then we accept $H_a$ and reject $H_0$, otherwise we fail to reject $H_0$.
```{r, include=FALSE}
library(nortest)
```
```{r}
lillie.test(olympic.lmfinal$residuals)
```
The p-value$=0.2332>\alpha$, thus we fail to reject $H_0$. Therefore, it is reasonable to assume that the error terms are distributed normally.

#Diagnostics
vif(olympic.lmfinal)

Influential Cases:
```{r}
#Influential cases
olympic.lm_inf=influence.measures(olympic.lmfinal)$is.inf
idx=which(apply(olympic.lm_inf,1,any))

Olympic[idx,]
```


APPENDIX:
A. Influential Cases by test:
```{r}
olympic.lm_inf[idx,]
```

